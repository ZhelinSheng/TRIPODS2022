{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is the TRIPODS2022 Derivatives group's k-derivative code. \n",
    "Given a function, this code takes k-number(s) of discrete derivative as regressors in order to predict the next numbers in that function's sequence.  Future experimentation will include testing a variety of functions, the number of predicted values, etc. to study how it affects predictive accuracy/variance and from that, find an ideal number of regressors to use that improves the performance of neural network prediction models. Additionally, study how differing function affects accuracy and define what makes a function \"complicated.\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "import pandas as pd\n",
    "import io\n",
    "import os\n",
    "import requests\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "import math\n",
    "from math import log\n",
    "import numpy as np \n",
    "import matplotlib \n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes another derivative for use in kthderiv below (list size decreases by 1)\n",
    "def derivative_new(my_list):\n",
    "    '''\n",
    "    Parameters:\n",
    "        my_list (list): list to take derivatives of\n",
    "    \n",
    "    Returns:\n",
    "        list containing differences of consecutive terms of my_list\n",
    "    '''\n",
    "    \n",
    "    return [my_list[i]-my_list[i-1] for i in range(1,len(my_list))]\n",
    "\n",
    "def kthderiv(extended_list, k, original_length):\n",
    "    '''\n",
    "    Parameters:\n",
    "        extended_list (list): list to take derivatives of plus at least k predictions\n",
    "        k (int): number of derivatives\n",
    "        original_length (int): length of original list\n",
    "    \n",
    "    Returns:\n",
    "        derivatives (numpy array): the ith column has the ith derivative of the list, up to the kth derivative\n",
    "    '''\n",
    "    \n",
    "    derivatives = extended_list[:original_length]\n",
    "    for i in range(1,k+1):\n",
    "        next_deriv = extended_list[:original_length + i]\n",
    "        for j in range(i):\n",
    "            next_deriv = derivative_new(next_deriv)\n",
    "        derivatives = np.column_stack((derivatives, next_deriv))\n",
    "    return derivatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a neural network with three hidden layers\n",
    "def forecast(x, y, x_pred, dim, layers, neurons):\n",
    "    '''\n",
    "    Trains a model on x and y and returns the array of predictions for x_pred\n",
    "    \n",
    "    Parameters:\n",
    "        x (numpy array): each row is a single input, contains a time column and the appropriate derivatives\n",
    "        y (numpy array): k x 1 array of all of the training labels\n",
    "        x_pred (numpy array): array with row length the same as x, used as input for predictions\n",
    "        dim (int): number of columns in x\n",
    "        layers (int): number of layers (excluding output)\n",
    "        neurons (int): total number of neurons\n",
    "    \n",
    "    Returns:\n",
    "        pred: predicted values for x-coordinates in x_pred\n",
    "    '''\n",
    "    \n",
    "    model = Sequential()\n",
    "    layer_size = 2**(layers - 1) * neurons//(2**(layers) - 1)\n",
    "    model.add(Dense(layer_size, input_dim=dim, activation='relu'))\n",
    "    \n",
    "    for i in range(layers - 1):\n",
    "        layer_size = layer_size//2\n",
    "        model.add(Dense(layer_size, activation='relu')) # Add hidden layer half the size of the previous one\n",
    "        \n",
    "    model.add(Dense(1)) # Output\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    model.fit(x,y,verbose=0,epochs=512)\n",
    "    pred = model.predict(x_pred) # generate predicted values (output)\n",
    "    return pred\n",
    "\n",
    "def kderiv_predict_nonrecursive_new(x, y, x_pred, k_derivs, pred_length, layers, neurons): \n",
    "    '''\n",
    "    Parameters:\n",
    "        x (list): x-coordinates of known values\n",
    "        y (list): known function values\n",
    "        x_pred (list): original x-coordinates plus x-coordinates we want predictions for\n",
    "        k_derivs (int): number of derivatives to use\n",
    "        pred_length (int): number of predictions\n",
    "        layers (int): number of layers (excluding output)\n",
    "        neurons (int): total number of neurons\n",
    "        \n",
    "    Returns:\n",
    "        updated_pred: new predictions based on derivative regressors\n",
    "    '''\n",
    "    \n",
    "    x_pred_extended = x_pred + [x_pred[-1] + 1 + i for i in range(k_derivs)] # extend x_pred by k_derivs to compensate for decrease in length from differentiating\n",
    "    pred_extended = forecast(x, y, x_pred_extended, 1, layers, neurons) # forecast function values for x-coordinates in x_pred_extended\n",
    "    pred_extended = list(np.squeeze(pred_extended)) # turn pred_extended into a list of floats\n",
    "    x_derivs = kthderiv(y + pred_extended[len(y):len(y) + k_derivs], k_derivs, len(y)) # create array of derivatives regressors\n",
    "    x_pred_multi = kthderiv(y + pred_extended[len(y):len(y) + pred_length + k_derivs], k_derivs, len(y) + pred_length) # create array to be fed into the network\n",
    "    if k_derivs > 0:\n",
    "        y = np.array(y)\n",
    "    updated_pred = forecast(x_derivs, y, x_pred_multi, k_derivs+1, layers, neurons) # forecast based on added regressors\n",
    "    return updated_pred # returns final predicted values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions based on a x-sized set, function in y, for a certain amount of real numbers\n",
    "x = [a for a in range(100)] # Edit range to vary size of training set \n",
    "y = [a**2 + math.sin(a)/10 for a in range(100)] # Edit function, number of predicted numbers\n",
    "x_pred = [a for a in range(110)] \n",
    "pred = kderiv_predict_nonrecursive_new(x, y, x_pred, 3, 10, 3, 1750)\n",
    "y_pred = np.array([a**2 + math.sin(a)/10 for a in range(110)])\n",
    "y = np.array(y)\n",
    "\n",
    "#Root-mean-square deviation (RMSD) calculates the difference between our values predicted and the true values\n",
    "score = np.sqrt(metrics.mean_squared_error(pred,y_pred))\n",
    "print(f\"Final score (RMSE): {score}\") \n",
    "# Caluclates the percent variance: increase or decrease in an account over time as a percentage of the total account value\n",
    "print(((y.std()-score)/y.std())*100, \"percent of variance explained\") # Higher variance (60-75%+) indicates stronger strength of association"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example to generate results for polynomials\n",
    "\n",
    "polynomial_results = {}\n",
    "for i in range(1,11):\n",
    "    for deriv in range(5):\n",
    "        for pred_length in range(10, 100, 10):\n",
    "            x = [a for a in range(100)]\n",
    "            y = [a**i for a in range(100)]\n",
    "            x_pred = [a for a in range(110)] \n",
    "            pred = kderiv_predict_nonrecursive_new(x, y, x_pred, deriv, pred_length, 3, 1750)\n",
    "            y_pred = np.array([a**i for a in range(110)])\n",
    "            y = np.array(y)\n",
    "            score = np.sqrt(metrics.mean_squared_error(pred,y_pred))\n",
    "            print(f\"Final score (RMSE): {score}\") \n",
    "            variance_explained = ((y.std()-score)/y.std())*100\n",
    "            print(variance_explained, \"percent of variance explained\")\n",
    "            polynomial_results[i, deriv, pred_length] = variance_explained"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
