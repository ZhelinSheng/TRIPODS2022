{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "base8fractal3dim.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "niDHfpk0XQ6D"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "42QRbJbb1YPC"
      },
      "outputs": [],
      "source": [
        "#libraries that we might need\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation\n",
        "import pandas as pd\n",
        "import io\n",
        "import os\n",
        "import requests\n",
        "import numpy as np\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "import math\n",
        "from math import log\n",
        "import numpy as np \n",
        "import matplotlib \n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Cantor 1 is the set with 2s and 0s in base 8. We make this set digit wise,\n",
        "#where n is the number of digits, not the number of iterations of the cantor set\n",
        "def cantor1(n):\n",
        "  points = []\n",
        "  if n==1:\n",
        "    return [0.0, 0.25]\n",
        "  else:\n",
        "    nstage = cantor1(n-1)\n",
        "    nstageplus = []\n",
        "    for i in nstage:\n",
        "      nstageplus.append(i+2*pow(1/8, n))\n",
        "    return  nstage + nstageplus"
      ],
      "metadata": {
        "id": "KHZSnpoC1pZa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Cantor 2 is the set with 0s and 4s in base 8. This is the same algorithm\n",
        "#as Cantor 1\n",
        "def cantor2(n):\n",
        "  points = []\n",
        "  if n==1:\n",
        "    return [0.0, 0.5]\n",
        "  else:\n",
        "    nstage = cantor2(n-1)\n",
        "    nstageplus = []\n",
        "    for i in nstage:\n",
        "      nstageplus.append(i+4*pow(1/8, n))\n",
        "    return  nstage + nstageplus"
      ],
      "metadata": {
        "id": "MpulhRHw5gry"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Cantor 3 is the set with 0s and 1s in base 8. This is the same algorithm\n",
        "#as Cantor 1\n",
        "def cantor3(n):\n",
        "  points = []\n",
        "  if n==1:\n",
        "    return [0.0, 0.125]\n",
        "  else:\n",
        "    nstage = cantor3(n-1)\n",
        "    nstageplus = []\n",
        "    for i in nstage:\n",
        "      nstageplus.append(i+pow(1/8, n))\n",
        "    return  nstage + nstageplus"
      ],
      "metadata": {
        "id": "6_XpN_UuXvPs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#This is a cartesian product of a cantor1 and cantor2 set\n",
        "def cantorproduct(n,m,k):\n",
        "  cantorset1 = cantor1(n)\n",
        "  cantorset2 = cantor2(m)\n",
        "  cantorset3 = cantor3(k)\n",
        "  product = []\n",
        "  for i in cantorset1:\n",
        "    for j in cantorset2:\n",
        "      for l in cantorset3:\n",
        "        product.append((i,j,l))\n",
        "  return product"
      ],
      "metadata": {
        "id": "Lj4q6ZxS7BPI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cantorproduct(2,2,2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3thZVsGa8pu0",
        "outputId": "68d83a13-36bc-455b-c14a-3c45f2629bcb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0.0, 0.0, 0.0),\n",
              " (0.0, 0.0, 0.125),\n",
              " (0.0, 0.0, 0.015625),\n",
              " (0.0, 0.0, 0.140625),\n",
              " (0.0, 0.5, 0.0),\n",
              " (0.0, 0.5, 0.125),\n",
              " (0.0, 0.5, 0.015625),\n",
              " (0.0, 0.5, 0.140625),\n",
              " (0.0, 0.0625, 0.0),\n",
              " (0.0, 0.0625, 0.125),\n",
              " (0.0, 0.0625, 0.015625),\n",
              " (0.0, 0.0625, 0.140625),\n",
              " (0.0, 0.5625, 0.0),\n",
              " (0.0, 0.5625, 0.125),\n",
              " (0.0, 0.5625, 0.015625),\n",
              " (0.0, 0.5625, 0.140625),\n",
              " (0.25, 0.0, 0.0),\n",
              " (0.25, 0.0, 0.125),\n",
              " (0.25, 0.0, 0.015625),\n",
              " (0.25, 0.0, 0.140625),\n",
              " (0.25, 0.5, 0.0),\n",
              " (0.25, 0.5, 0.125),\n",
              " (0.25, 0.5, 0.015625),\n",
              " (0.25, 0.5, 0.140625),\n",
              " (0.25, 0.0625, 0.0),\n",
              " (0.25, 0.0625, 0.125),\n",
              " (0.25, 0.0625, 0.015625),\n",
              " (0.25, 0.0625, 0.140625),\n",
              " (0.25, 0.5625, 0.0),\n",
              " (0.25, 0.5625, 0.125),\n",
              " (0.25, 0.5625, 0.015625),\n",
              " (0.25, 0.5625, 0.140625),\n",
              " (0.03125, 0.0, 0.0),\n",
              " (0.03125, 0.0, 0.125),\n",
              " (0.03125, 0.0, 0.015625),\n",
              " (0.03125, 0.0, 0.140625),\n",
              " (0.03125, 0.5, 0.0),\n",
              " (0.03125, 0.5, 0.125),\n",
              " (0.03125, 0.5, 0.015625),\n",
              " (0.03125, 0.5, 0.140625),\n",
              " (0.03125, 0.0625, 0.0),\n",
              " (0.03125, 0.0625, 0.125),\n",
              " (0.03125, 0.0625, 0.015625),\n",
              " (0.03125, 0.0625, 0.140625),\n",
              " (0.03125, 0.5625, 0.0),\n",
              " (0.03125, 0.5625, 0.125),\n",
              " (0.03125, 0.5625, 0.015625),\n",
              " (0.03125, 0.5625, 0.140625),\n",
              " (0.28125, 0.0, 0.0),\n",
              " (0.28125, 0.0, 0.125),\n",
              " (0.28125, 0.0, 0.015625),\n",
              " (0.28125, 0.0, 0.140625),\n",
              " (0.28125, 0.5, 0.0),\n",
              " (0.28125, 0.5, 0.125),\n",
              " (0.28125, 0.5, 0.015625),\n",
              " (0.28125, 0.5, 0.140625),\n",
              " (0.28125, 0.0625, 0.0),\n",
              " (0.28125, 0.0625, 0.125),\n",
              " (0.28125, 0.0625, 0.015625),\n",
              " (0.28125, 0.0625, 0.140625),\n",
              " (0.28125, 0.5625, 0.0),\n",
              " (0.28125, 0.5625, 0.125),\n",
              " (0.28125, 0.5625, 0.015625),\n",
              " (0.28125, 0.5625, 0.140625)]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#This is a sample function that we are going to train the function on\n",
        "#we chose the distance function, but it doesn't actually matter\n",
        "def samplefunction(product):\n",
        "  i,j, k = product\n",
        "  return math.sqrt(i*i+j*j+k*k)"
      ],
      "metadata": {
        "id": "mBx2PHzB9CK6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#This is just a function that puts the data into data, labels, compressed data,\n",
        "#and labels for the compressed data \n",
        "def createsets(n,m,o,f):\n",
        "  onedim = [] #dimension reduced input data\n",
        "  onedimout = [] #dimension reduced labels\n",
        "  threedim = [] #fully dimensional input data\n",
        "  threedimout = [] #fully dimensional labels\n",
        "  productlist = cantorproduct(n,m,o)\n",
        "  for i in productlist:\n",
        "    a,b,c = i\n",
        "    threedim.append([a,b,c])\n",
        "    threedimout.append(f(i))\n",
        "    onedim.append(a+b+c)\n",
        "    onedimout.append(f(i))\n",
        "  return onedim, onedimout, threedim, threedimout"
      ],
      "metadata": {
        "id": "Zums2y8V9x0k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "createsets(2,2,2, samplefunction)"
      ],
      "metadata": {
        "id": "3RGbiGFE-4wf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2de2060-2288-4939-8501-f5b47aa98cfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([0.0,\n",
              "  0.125,\n",
              "  0.015625,\n",
              "  0.140625,\n",
              "  0.5,\n",
              "  0.625,\n",
              "  0.515625,\n",
              "  0.640625,\n",
              "  0.0625,\n",
              "  0.1875,\n",
              "  0.078125,\n",
              "  0.203125,\n",
              "  0.5625,\n",
              "  0.6875,\n",
              "  0.578125,\n",
              "  0.703125,\n",
              "  0.25,\n",
              "  0.375,\n",
              "  0.265625,\n",
              "  0.390625,\n",
              "  0.75,\n",
              "  0.875,\n",
              "  0.765625,\n",
              "  0.890625,\n",
              "  0.3125,\n",
              "  0.4375,\n",
              "  0.328125,\n",
              "  0.453125,\n",
              "  0.8125,\n",
              "  0.9375,\n",
              "  0.828125,\n",
              "  0.953125,\n",
              "  0.03125,\n",
              "  0.15625,\n",
              "  0.046875,\n",
              "  0.171875,\n",
              "  0.53125,\n",
              "  0.65625,\n",
              "  0.546875,\n",
              "  0.671875,\n",
              "  0.09375,\n",
              "  0.21875,\n",
              "  0.109375,\n",
              "  0.234375,\n",
              "  0.59375,\n",
              "  0.71875,\n",
              "  0.609375,\n",
              "  0.734375,\n",
              "  0.28125,\n",
              "  0.40625,\n",
              "  0.296875,\n",
              "  0.421875,\n",
              "  0.78125,\n",
              "  0.90625,\n",
              "  0.796875,\n",
              "  0.921875,\n",
              "  0.34375,\n",
              "  0.46875,\n",
              "  0.359375,\n",
              "  0.484375,\n",
              "  0.84375,\n",
              "  0.96875,\n",
              "  0.859375,\n",
              "  0.984375],\n",
              " [0.0,\n",
              "  0.125,\n",
              "  0.015625,\n",
              "  0.140625,\n",
              "  0.5,\n",
              "  0.5153882032022076,\n",
              "  0.5002440810494413,\n",
              "  0.5193990668310832,\n",
              "  0.0625,\n",
              "  0.13975424859373686,\n",
              "  0.06442352540027595,\n",
              "  0.15388840315306412,\n",
              "  0.5625,\n",
              "  0.5762215285808054,\n",
              "  0.5627169720427846,\n",
              "  0.5798117286024835,\n",
              "  0.25,\n",
              "  0.2795084971874737,\n",
              "  0.25048780534189685,\n",
              "  0.28683687110446593,\n",
              "  0.5590169943749475,\n",
              "  0.57282196186948,\n",
              "  0.559235317755415,\n",
              "  0.5764333358030224,\n",
              "  0.2576941016011038,\n",
              "  0.28641098093474,\n",
              "  0.258167369404036,\n",
              "  0.293567097313374,\n",
              "  0.6155536126122565,\n",
              "  0.6281172263200556,\n",
              "  0.6157518904761885,\n",
              "  0.6314124172242734,\n",
              "  0.03125,\n",
              "  0.1288470508005519,\n",
              "  0.034938562148434216,\n",
              "  0.14405538214520136,\n",
              "  0.5009756106837937,\n",
              "  0.516334738808072,\n",
              "  0.501219216635795,\n",
              "  0.5203383064170848,\n",
              "  0.06987712429686843,\n",
              "  0.14320549046737,\n",
              "  0.071602745233685,\n",
              "  0.1570293065800139,\n",
              "  0.5633673867912483,\n",
              "  0.5770682910193559,\n",
              "  0.5635840249022323,\n",
              "  0.5806532555019389,\n",
              "  0.28125,\n",
              "  0.30777680630612825,\n",
              "  0.28168369339562416,\n",
              "  0.31444705933590794,\n",
              "  0.5736737422089319,\n",
              "  0.587134194626748,\n",
              "  0.5738864897564674,\n",
              "  0.5906580678573687,\n",
              "  0.2881107642904027,\n",
              "  0.3140586131600278,\n",
              "  0.28853414550967793,\n",
              "  0.3205981957606749,\n",
              "  0.6288941186718159,\n",
              "  0.6411963915213498,\n",
              "  0.6290881918499186,\n",
              "  0.644424707103165],\n",
              " [[0.0, 0.0, 0.0],\n",
              "  [0.0, 0.0, 0.125],\n",
              "  [0.0, 0.0, 0.015625],\n",
              "  [0.0, 0.0, 0.140625],\n",
              "  [0.0, 0.5, 0.0],\n",
              "  [0.0, 0.5, 0.125],\n",
              "  [0.0, 0.5, 0.015625],\n",
              "  [0.0, 0.5, 0.140625],\n",
              "  [0.0, 0.0625, 0.0],\n",
              "  [0.0, 0.0625, 0.125],\n",
              "  [0.0, 0.0625, 0.015625],\n",
              "  [0.0, 0.0625, 0.140625],\n",
              "  [0.0, 0.5625, 0.0],\n",
              "  [0.0, 0.5625, 0.125],\n",
              "  [0.0, 0.5625, 0.015625],\n",
              "  [0.0, 0.5625, 0.140625],\n",
              "  [0.25, 0.0, 0.0],\n",
              "  [0.25, 0.0, 0.125],\n",
              "  [0.25, 0.0, 0.015625],\n",
              "  [0.25, 0.0, 0.140625],\n",
              "  [0.25, 0.5, 0.0],\n",
              "  [0.25, 0.5, 0.125],\n",
              "  [0.25, 0.5, 0.015625],\n",
              "  [0.25, 0.5, 0.140625],\n",
              "  [0.25, 0.0625, 0.0],\n",
              "  [0.25, 0.0625, 0.125],\n",
              "  [0.25, 0.0625, 0.015625],\n",
              "  [0.25, 0.0625, 0.140625],\n",
              "  [0.25, 0.5625, 0.0],\n",
              "  [0.25, 0.5625, 0.125],\n",
              "  [0.25, 0.5625, 0.015625],\n",
              "  [0.25, 0.5625, 0.140625],\n",
              "  [0.03125, 0.0, 0.0],\n",
              "  [0.03125, 0.0, 0.125],\n",
              "  [0.03125, 0.0, 0.015625],\n",
              "  [0.03125, 0.0, 0.140625],\n",
              "  [0.03125, 0.5, 0.0],\n",
              "  [0.03125, 0.5, 0.125],\n",
              "  [0.03125, 0.5, 0.015625],\n",
              "  [0.03125, 0.5, 0.140625],\n",
              "  [0.03125, 0.0625, 0.0],\n",
              "  [0.03125, 0.0625, 0.125],\n",
              "  [0.03125, 0.0625, 0.015625],\n",
              "  [0.03125, 0.0625, 0.140625],\n",
              "  [0.03125, 0.5625, 0.0],\n",
              "  [0.03125, 0.5625, 0.125],\n",
              "  [0.03125, 0.5625, 0.015625],\n",
              "  [0.03125, 0.5625, 0.140625],\n",
              "  [0.28125, 0.0, 0.0],\n",
              "  [0.28125, 0.0, 0.125],\n",
              "  [0.28125, 0.0, 0.015625],\n",
              "  [0.28125, 0.0, 0.140625],\n",
              "  [0.28125, 0.5, 0.0],\n",
              "  [0.28125, 0.5, 0.125],\n",
              "  [0.28125, 0.5, 0.015625],\n",
              "  [0.28125, 0.5, 0.140625],\n",
              "  [0.28125, 0.0625, 0.0],\n",
              "  [0.28125, 0.0625, 0.125],\n",
              "  [0.28125, 0.0625, 0.015625],\n",
              "  [0.28125, 0.0625, 0.140625],\n",
              "  [0.28125, 0.5625, 0.0],\n",
              "  [0.28125, 0.5625, 0.125],\n",
              "  [0.28125, 0.5625, 0.015625],\n",
              "  [0.28125, 0.5625, 0.140625]],\n",
              " [0.0,\n",
              "  0.125,\n",
              "  0.015625,\n",
              "  0.140625,\n",
              "  0.5,\n",
              "  0.5153882032022076,\n",
              "  0.5002440810494413,\n",
              "  0.5193990668310832,\n",
              "  0.0625,\n",
              "  0.13975424859373686,\n",
              "  0.06442352540027595,\n",
              "  0.15388840315306412,\n",
              "  0.5625,\n",
              "  0.5762215285808054,\n",
              "  0.5627169720427846,\n",
              "  0.5798117286024835,\n",
              "  0.25,\n",
              "  0.2795084971874737,\n",
              "  0.25048780534189685,\n",
              "  0.28683687110446593,\n",
              "  0.5590169943749475,\n",
              "  0.57282196186948,\n",
              "  0.559235317755415,\n",
              "  0.5764333358030224,\n",
              "  0.2576941016011038,\n",
              "  0.28641098093474,\n",
              "  0.258167369404036,\n",
              "  0.293567097313374,\n",
              "  0.6155536126122565,\n",
              "  0.6281172263200556,\n",
              "  0.6157518904761885,\n",
              "  0.6314124172242734,\n",
              "  0.03125,\n",
              "  0.1288470508005519,\n",
              "  0.034938562148434216,\n",
              "  0.14405538214520136,\n",
              "  0.5009756106837937,\n",
              "  0.516334738808072,\n",
              "  0.501219216635795,\n",
              "  0.5203383064170848,\n",
              "  0.06987712429686843,\n",
              "  0.14320549046737,\n",
              "  0.071602745233685,\n",
              "  0.1570293065800139,\n",
              "  0.5633673867912483,\n",
              "  0.5770682910193559,\n",
              "  0.5635840249022323,\n",
              "  0.5806532555019389,\n",
              "  0.28125,\n",
              "  0.30777680630612825,\n",
              "  0.28168369339562416,\n",
              "  0.31444705933590794,\n",
              "  0.5736737422089319,\n",
              "  0.587134194626748,\n",
              "  0.5738864897564674,\n",
              "  0.5906580678573687,\n",
              "  0.2881107642904027,\n",
              "  0.3140586131600278,\n",
              "  0.28853414550967793,\n",
              "  0.3205981957606749,\n",
              "  0.6288941186718159,\n",
              "  0.6411963915213498,\n",
              "  0.6290881918499186,\n",
              "  0.644424707103165])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#getting our data into np arrays so that they can be tensorflowed\n",
        "onedim, onedimout, threedim, threedimout = createsets(5,5,5, samplefunction)\n",
        "x1 = np.array(onedim)\n",
        "y1 = np.array(onedimout)\n",
        "x1_train, x1_test, y1_train, y1_test = train_test_split(x1,y1, test_size=0.2, shuffle=True)\n",
        "x2 = np.array(threedim)\n",
        "y2 = np.array(threedimout)\n",
        "x2_train, x2_test, y2_train, y2_test = train_test_split(x2,y2, test_size=0.2, shuffle=True)\n"
      ],
      "metadata": {
        "id": "1MEiV0OLbsjv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model for the 1 dimensional data\n",
        "model1 = Sequential()\n",
        "model1.add(Dense(3000, input_dim=1, activation='relu')) # Hidden 1\n",
        "model1.add(Dense(1500, activation='relu')) # Hidden 2\n",
        "model1.add(Dense(1)) # Output\n",
        "model1.compile(loss='mean_squared_error', optimizer='adam')\n",
        "model1.fit(x1_train,y1_train,verbose=2,epochs=16)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eOnpFNcUjc8Z",
        "outputId": "c2f72f26-0dbc-4d82-e8c8-d94c2de6dfe2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/16\n",
            "820/820 - 2s - loss: 0.0019 - 2s/epoch - 3ms/step\n",
            "Epoch 2/16\n",
            "820/820 - 2s - loss: 8.9168e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 3/16\n",
            "820/820 - 2s - loss: 7.2128e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 4/16\n",
            "820/820 - 2s - loss: 6.1064e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 5/16\n",
            "820/820 - 2s - loss: 5.6852e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 6/16\n",
            "820/820 - 2s - loss: 5.6521e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 7/16\n",
            "820/820 - 2s - loss: 5.6013e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 8/16\n",
            "820/820 - 2s - loss: 4.7876e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 9/16\n",
            "820/820 - 2s - loss: 4.8778e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 10/16\n",
            "820/820 - 2s - loss: 4.6682e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 11/16\n",
            "820/820 - 2s - loss: 4.0483e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 12/16\n",
            "820/820 - 2s - loss: 4.2248e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 13/16\n",
            "820/820 - 2s - loss: 3.9089e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 14/16\n",
            "820/820 - 2s - loss: 3.9852e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 15/16\n",
            "820/820 - 2s - loss: 3.4510e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 16/16\n",
            "820/820 - 2s - loss: 3.4329e-04 - 2s/epoch - 3ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f739e70e110>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#model for the two dimensional input data\n",
        "model2 = Sequential()\n",
        "model2.add(Dense(3000, input_dim=3, activation='relu')) # Hidden 1\n",
        "model2.add(Dense(1500, activation='relu')) # Hidden 2\n",
        "model2.add(Dense(1)) # Output\n",
        "model2.compile(loss='mean_squared_error', optimizer='adam')\n",
        "model2.fit(x2_train, y2_train,verbose=2,epochs=16)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E0YML0hbmrZ_",
        "outputId": "395de441-4dd6-4fb0-ba85-ac20e6a4cbe4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/16\n",
            "820/820 - 2s - loss: 5.6422e-04 - 2s/epoch - 3ms/step\n",
            "Epoch 2/16\n",
            "820/820 - 2s - loss: 3.7475e-07 - 2s/epoch - 3ms/step\n",
            "Epoch 3/16\n",
            "820/820 - 2s - loss: 4.8362e-07 - 2s/epoch - 3ms/step\n",
            "Epoch 4/16\n",
            "820/820 - 2s - loss: 1.7313e-05 - 2s/epoch - 3ms/step\n",
            "Epoch 5/16\n",
            "820/820 - 2s - loss: 2.1379e-05 - 2s/epoch - 3ms/step\n",
            "Epoch 6/16\n",
            "820/820 - 2s - loss: 2.2473e-05 - 2s/epoch - 3ms/step\n",
            "Epoch 7/16\n",
            "820/820 - 2s - loss: 1.0705e-05 - 2s/epoch - 3ms/step\n",
            "Epoch 8/16\n",
            "820/820 - 2s - loss: 1.1940e-05 - 2s/epoch - 3ms/step\n",
            "Epoch 9/16\n",
            "820/820 - 2s - loss: 2.8776e-05 - 2s/epoch - 3ms/step\n",
            "Epoch 10/16\n",
            "820/820 - 2s - loss: 3.6305e-06 - 2s/epoch - 3ms/step\n",
            "Epoch 11/16\n",
            "820/820 - 2s - loss: 1.0547e-05 - 2s/epoch - 3ms/step\n",
            "Epoch 12/16\n",
            "820/820 - 2s - loss: 9.0526e-06 - 2s/epoch - 3ms/step\n",
            "Epoch 13/16\n",
            "820/820 - 2s - loss: 1.1614e-05 - 2s/epoch - 3ms/step\n",
            "Epoch 14/16\n",
            "820/820 - 3s - loss: 1.2025e-05 - 3s/epoch - 4ms/step\n",
            "Epoch 15/16\n",
            "820/820 - 2s - loss: 9.7970e-07 - 2s/epoch - 3ms/step\n",
            "Epoch 16/16\n",
            "820/820 - 2s - loss: 1.2367e-05 - 2s/epoch - 3ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f73842c3110>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#test data for the 1 dimensional model\n",
        "pred1 = model1.predict(x1_test)\n",
        "score1 = np.sqrt(metrics.mean_squared_error(pred1,y1_test))\n",
        "pvariance1 = (y1.std()-score1)/y1.std()\n",
        "score1, pvariance1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1eHvZS3OlkQV",
        "outputId": "4911ee8f-11c4-438c-e53c-10399d306b89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.0213048408773247, 0.897474494860271)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#test data for the 2 dimensional model\n",
        "pred2 = model2.predict(x2_test)\n",
        "score2 = np.sqrt(metrics.mean_squared_error(pred2,y2_test))\n",
        "pvariance2 = (y2.std()-score2)/y2.std()\n",
        "score2, pvariance2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7NELUaqimzG6",
        "outputId": "1d2bb2fd-23a9-4ada-ce5d-8f094f6f53ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.0007938074090394367, 0.9961799524312782)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    }
  ]
}